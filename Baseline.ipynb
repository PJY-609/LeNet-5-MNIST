{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "D:\\anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from load_data import load_data\n",
    "train, valid, test  = load_data('./mnist.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_X_train = train[0]\n",
    "raw_y_train = train[1]\n",
    "raw_X_val = valid[0]\n",
    "raw_y_val = valid[1]\n",
    "raw_X_test = test[0]\n",
    "raw_y_test = test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784) (10000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(raw_X_train.shape, raw_X_val.shape, raw_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bacbf67940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "I = raw_X_train[0]\n",
    "I = I.reshape(28, 28)\n",
    "plt.imshow(I*256, cmap='gray')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train_samples = raw_X_train.shape[0]\n",
    "n_val_samples = raw_X_val.shape[0]\n",
    "n_test_samples = raw_X_test.shape[0]\n",
    "\n",
    "X_train = raw_X_train.reshape(n_train_samples, 28, 28, 1)\n",
    "X_val = raw_X_val.reshape(n_val_samples, 28, 28, 1)\n",
    "X_test = raw_X_test.reshape(n_test_samples, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,) (10000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(raw_y_train.shape, raw_y_val.shape, raw_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import utils\n",
    "Y_train = utils.to_categorical(raw_y_train, num_classes=10)\n",
    "Y_val = utils.to_categorical(raw_y_val, num_classes=10)\n",
    "Y_test = utils.to_categorical(raw_y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10) (10000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "def mnist_model():\n",
    "    X_input = Input(shape=(28, 28, 1), name='input')\n",
    "    \n",
    "    X = Conv2D(6, (5, 5), padding='same')(X_input)\n",
    "    X =Activation('relu')(X)\n",
    "    X= MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
    "    \n",
    "    X = Conv2D(16,(5, 5), padding=\"same\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(120)(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    X = Dense(84)(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    X = Dense(10)(X)\n",
    "    X_output = Activation(\"softmax\")(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 16)        2416      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               94200     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                850       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 107,786\n",
      "Trainable params: 107,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_model = mnist_model()\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "mnist_model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(lr=0.001), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "csv_logger = CSVLogger('training.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 2.2996 - acc: 0.1010 - val_loss: 2.2882 - val_acc: 0.1028\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.2773 - acc: 0.1367 - val_loss: 2.2637 - val_acc: 0.1826\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2483 - acc: 0.2350 - val_loss: 2.2256 - val_acc: 0.2921\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 2.1938 - acc: 0.3370 - val_loss: 2.1458 - val_acc: 0.3792\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.0691 - acc: 0.4236 - val_loss: 1.9519 - val_acc: 0.5029\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 1.7490 - acc: 0.5960 - val_loss: 1.4584 - val_acc: 0.7305\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 1.1672 - acc: 0.7546 - val_loss: 0.8564 - val_acc: 0.8193\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.7339 - acc: 0.8205 - val_loss: 0.5707 - val_acc: 0.8587\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.5506 - acc: 0.8530 - val_loss: 0.4530 - val_acc: 0.8792\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.4649 - acc: 0.8711 - val_loss: 0.3917 - val_acc: 0.8906\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.4132 - acc: 0.8832 - val_loss: 0.3558 - val_acc: 0.9019\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.3786 - acc: 0.8919 - val_loss: 0.3281 - val_acc: 0.9065\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3532 - acc: 0.8986 - val_loss: 0.3067 - val_acc: 0.9093\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.3336 - acc: 0.9035 - val_loss: 0.2918 - val_acc: 0.9149\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3175 - acc: 0.9076 - val_loss: 0.2792 - val_acc: 0.9157\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.3038 - acc: 0.9114 - val_loss: 0.2674 - val_acc: 0.9194\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.2922 - acc: 0.9137 - val_loss: 0.2594 - val_acc: 0.9208\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.2813 - acc: 0.9162 - val_loss: 0.2507 - val_acc: 0.9240\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.2713 - acc: 0.9184 - val_loss: 0.2394 - val_acc: 0.9290\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.2625 - acc: 0.9223 - val_loss: 0.2341 - val_acc: 0.9291\n"
     ]
    }
   ],
   "source": [
    "history = mnist_model.fit(X_train, Y_train, validation_data=[X_val, Y_val], batch_size=128, epochs=20, verbose=1, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 588us/step\n",
      "accuracy: 92.56%\n"
     ]
    }
   ],
   "source": [
    "(loss, accuracy) = mnist_model.evaluate(X_test, Y_test, batch_size=128, verbose=1)\n",
    "print(\"accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [2.298287029342651, 2.2784478147888185, 2.254126477813721, 2.2152049073791504, 2.13812848526001, 1.9601714239883423, 1.5360724259185792, 0.9779956140136719, 0.6778259690666198, 0.5447483205604553, 0.4722065202140808, 0.4246502883052826, 0.3900753437900543, 0.3629552750301361, 0.34063414200782777, 0.32239456194877625, 0.30621487765312194, 0.2919089814376831, 0.2795747111606598, 0.2686596245908737], 'acc': [0.09091999999523163, 0.14325999999046327, 0.22543999999046327, 0.3178999999809265, 0.4321999999809265, 0.591780000038147, 0.7079400000190735, 0.7782400000190735, 0.8247999999809266, 0.8502799999809265, 0.865539999961853, 0.877640000038147, 0.886640000038147, 0.8937599999809265, 0.9001000000190735, 0.905280000038147, 0.90886, 0.9133800000190735, 0.916980000038147, 0.920499999961853]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('training.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch      acc      loss  val_acc  val_loss\n",
      "0       0  0.10102  2.299579   0.1028  2.288184\n",
      "1       1  0.13672  2.277261   0.1826  2.263725\n",
      "2       2  0.23502  2.248286   0.2921  2.225622\n",
      "3       3  0.33702  2.193802   0.3792  2.145845\n",
      "4       4  0.42360  2.069126   0.5029  1.951863\n",
      "5       5  0.59602  1.748973   0.7305  1.458445\n",
      "6       6  0.75460  1.167195   0.8193  0.856400\n",
      "7       7  0.82050  0.733897   0.8587  0.570713\n",
      "8       8  0.85298  0.550592   0.8792  0.452985\n",
      "9       9  0.87114  0.464943   0.8906  0.391676\n",
      "10     10  0.88320  0.413164   0.9019  0.355783\n",
      "11     11  0.89194  0.378619   0.9065  0.328067\n",
      "12     12  0.89860  0.353230   0.9093  0.306685\n",
      "13     13  0.90352  0.333646   0.9149  0.291751\n",
      "14     14  0.90756  0.317508   0.9157  0.279207\n",
      "15     15  0.91138  0.303796   0.9194  0.267400\n",
      "16     16  0.91368  0.292196   0.9208  0.259405\n",
      "17     17  0.91624  0.281276   0.9240  0.250704\n",
      "18     18  0.91842  0.271279   0.9290  0.239406\n",
      "19     19  0.92228  0.262523   0.9291  0.234122\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
