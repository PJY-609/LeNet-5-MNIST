{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "D:\\anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from load_data import load_data\n",
    "train, valid, test  = load_data('./mnist.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_X_train = train[0]\n",
    "raw_y_train = train[1]\n",
    "raw_X_val = valid[0]\n",
    "raw_y_val = valid[1]\n",
    "raw_X_test = test[0]\n",
    "raw_y_test = test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train_samples = raw_X_train.shape[0]\n",
    "n_val_samples = raw_X_val.shape[0]\n",
    "n_test_samples = raw_X_test.shape[0]\n",
    "\n",
    "X_train = raw_X_train.reshape(n_train_samples, 28, 28, 1)\n",
    "X_val = raw_X_val.reshape(n_val_samples, 28, 28, 1)\n",
    "X_test = raw_X_test.reshape(n_test_samples, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import utils\n",
    "Y_train = utils.to_categorical(raw_y_train, num_classes=10)\n",
    "Y_val = utils.to_categorical(raw_y_val, num_classes=10)\n",
    "Y_test = utils.to_categorical(raw_y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "def mnist_model():\n",
    "    X_input = Input(shape=(28, 28, 1), name='input')\n",
    "    \n",
    "    X = Conv2D(6, (5, 5), padding='same', kernel_initializer='he_normal', bias_initializer='zeros')(X_input)\n",
    "    X =Activation('relu')(X)\n",
    "    X= MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
    "    \n",
    "    X = Conv2D(16,(5, 5), padding=\"same\", kernel_initializer='he_normal', bias_initializer='zeros')(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(120, kernel_initializer='he_normal', bias_initializer='zeros')(X)\n",
    "    X = Dropout(rate=0.3)(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    X = Dense(84, kernel_initializer='he_normal', bias_initializer='zeros')(X)\n",
    "    X = Dropout(rate=0.3)(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    X = Dense(10)(X)\n",
    "    X_output = Activation(\"softmax\")(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "dropout_model = mnist_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "dropout_model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(lr=0.001), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "csv_logger = CSVLogger('dropout_training.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.4394 - acc: 0.8585 - val_loss: 0.0924 - val_acc: 0.9714\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1231 - acc: 0.9638 - val_loss: 0.0612 - val_acc: 0.9813\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.0828 - acc: 0.9756 - val_loss: 0.0561 - val_acc: 0.9831\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.0655 - acc: 0.9809 - val_loss: 0.0510 - val_acc: 0.9860\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.0542 - acc: 0.9846 - val_loss: 0.0494 - val_acc: 0.9867\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.0474 - acc: 0.9863 - val_loss: 0.0480 - val_acc: 0.9875\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.0428 - acc: 0.9875 - val_loss: 0.0610 - val_acc: 0.9855\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.0387 - acc: 0.9891 - val_loss: 0.0504 - val_acc: 0.9874\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.0346 - acc: 0.9903 - val_loss: 0.0483 - val_acc: 0.9885\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.0325 - acc: 0.9909 - val_loss: 0.0479 - val_acc: 0.9895\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0296 - acc: 0.9912 - val_loss: 0.0507 - val_acc: 0.9884\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0289 - acc: 0.9914 - val_loss: 0.0554 - val_acc: 0.9878\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0274 - acc: 0.9921 - val_loss: 0.0571 - val_acc: 0.9895\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0277 - acc: 0.9924 - val_loss: 0.0526 - val_acc: 0.9890\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.0262 - acc: 0.9924 - val_loss: 0.0568 - val_acc: 0.9882\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0249 - acc: 0.9930 - val_loss: 0.0692 - val_acc: 0.9878\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0259 - acc: 0.9930 - val_loss: 0.0541 - val_acc: 0.9861\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.0257 - acc: 0.9931 - val_loss: 0.0645 - val_acc: 0.9881\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.0231 - acc: 0.9936 - val_loss: 0.0612 - val_acc: 0.9885\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.0258 - acc: 0.9931 - val_loss: 0.0763 - val_acc: 0.9887\n"
     ]
    }
   ],
   "source": [
    "history = dropout_model.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=128, epochs=20, verbose=1, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 643us/step\n",
      "accuracy: 98.97%\n"
     ]
    }
   ],
   "source": [
    "(loss, accuracy) = dropout_model.evaluate(X_test, Y_test, batch_size=128, verbose=1)\n",
    "print(\"accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch      acc      loss  val_acc  val_loss\n",
      "0       0  0.85850  0.439379   0.9714  0.092388\n",
      "1       1  0.96384  0.123074   0.9813  0.061244\n",
      "2       2  0.97560  0.082817   0.9831  0.056116\n",
      "3       3  0.98088  0.065493   0.9860  0.051014\n",
      "4       4  0.98464  0.054220   0.9867  0.049374\n",
      "5       5  0.98632  0.047377   0.9875  0.047976\n",
      "6       6  0.98754  0.042756   0.9855  0.061049\n",
      "7       7  0.98906  0.038734   0.9874  0.050419\n",
      "8       8  0.99028  0.034596   0.9885  0.048295\n",
      "9       9  0.99086  0.032528   0.9895  0.047911\n",
      "10     10  0.99124  0.029571   0.9884  0.050683\n",
      "11     11  0.99140  0.028860   0.9878  0.055412\n",
      "12     12  0.99210  0.027432   0.9895  0.057079\n",
      "13     13  0.99244  0.027656   0.9890  0.052614\n",
      "14     14  0.99244  0.026229   0.9882  0.056848\n",
      "15     15  0.99296  0.024921   0.9878  0.069219\n",
      "16     16  0.99302  0.025869   0.9861  0.054103\n",
      "17     17  0.99306  0.025731   0.9881  0.064482\n",
      "18     18  0.99360  0.023096   0.9885  0.061186\n",
      "19     19  0.99310  0.025815   0.9887  0.076271\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dropout_training.log')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
